package pagerank;

import java.io.IOException;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class SpamMass 
{
	static boolean debug = false;
	public static class Map 
	extends Mapper<LongWritable,Text,Text,Text>
	{
		private boolean trustRank;//are we mapping normal page rank or trust rankmatrix M or N
		private Path path;
		private String trPath;
		
		/**
		 * The Hadoop Map-Reduce framework spawns one map
		 * task for each InputSplit generated by the InputFormat 
		 * for this job. The framework first calls setup, 
		 * followed by map for each key/value pair in the 
		 * InputSplit
		 */
		public void setup(Context context)
		{
			Configuration conf = context.getConfiguration();
			trPath = conf.get("trPath");

			FileSplit split = (FileSplit)context.getInputSplit();
			path = split.getPath();
			trustRank = path.toString().contains(trPath);
		
			if (debug)
			{
				System.out.println("Is trust rank " + trustRank + " for "+ path);
			}
		}
		
		public void map(LongWritable key,Text val,Context context) throws IOException, InterruptedException
		{
			Text outputKey = new Text();
			Text outputValue = new Text();
			outputKey.set(key.toString());
			if (trustRank)
			{				
				outputValue.set("t,"+val);
			}
			else
			{
				outputValue.set("r," + val);
			}
			context.write(outputKey,  outputValue);
		}
	}
	
	public static class Reduce extends Reducer<Text,
	Text,Text,Text>
	{		
		public void setup(Context context)
		{
				
		}
		
		public void reduce(Text key,
				Iterable<Text> values,Context context) throws IOException, InterruptedException
		{
			String[] value;
			double r=1.0,sm = 0.0;
			for (Text val : values)
			{				
				value = val.toString().split(",");
				if (value[0].equals("t"))
				{
					sm -= Double.parseDouble(value[1].split("\t")[1]);
				}
				else
				{
					r = Double.parseDouble(value[1].split("\t")[1]);
					sm += r;										
				}
			}
			
			sm = sm/r;
			if (debug)
			{
				System.out.println("key is " + key);
				System.out.println("r is " + r);
				System.out.println("spam mass is " + sm);
			}
			context.write(key,new Text(sm + ""));
		}
	}
	
	 public static void calcSpamMass(Path prPath, Path trPath,Path outputPath)
		      throws Exception 
		      {
		 Configuration conf = new Configuration();
		 conf.set("trPath",trPath.toString());
		 Job job = new Job(conf);
		 job.setJarByClass(SpamMass.class);
		 job.setMapperClass(Map.class);
		 job.setReducerClass(Reduce.class);
		 
		// job.setInputFormatClass(KeyValueTextInputFormat.class);

		 job.setMapOutputKeyClass(Text.class);
		 job.setMapOutputValueClass(Text.class);
		    
		 FileInputFormat.addInputPath(job, prPath);
		 FileInputFormat.addInputPath(job, trPath);
		 FileSystem fs = FileSystem.get(conf);
		 fs.delete(outputPath);
		 FileOutputFormat.setOutputPath(job, outputPath);
		 
		 if (!job.waitForCompletion(true)) {
		      throw new Exception("Job failed");
		 }
		      }
}