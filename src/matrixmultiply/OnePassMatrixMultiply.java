package matrixmultiply;
import java.io.IOException;
import java.util.HashMap;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.FileSystem;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Partitioner;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.input.FileSplit;
import org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;
import org.apache.hadoop.mapreduce.lib.output.SequenceFileOutputFormat;


public class OnePassMatrixMultiply 
{
	public static class MapGrouped 
	extends Mapper<MatrixMultiply.IndexPair, 
	DoubleWritable,Text,Text>
	{
		private boolean matrixM;//are we mapping matrix M or N
		private Path path;
		private String inputPathM,inputPathN;
		private int I,K;//num rows, num cols
		private int numGroups,numGroupRows,numGroupCols;
		private boolean debug = false;
		
		/**
		 * The Hadoop Map-Reduce framework spawns one map
		 * task for each InputSplit generated by the InputFormat 
		 * for this job. The framework first calls setup, 
		 * followed by map for each key/value pair in the 
		 * InputSplit
		 */
		public void setup(Context context)
		{
			Configuration conf = context.getConfiguration();
			inputPathM = conf.get("inputPathM");
			inputPathN = conf.get("inputPathN");
			debug = Boolean.parseBoolean(conf.get("debug"));
			FileSplit split = (FileSplit)context.getInputSplit();
			path = split.getPath();
			matrixM = path.toString().contains(inputPathM);
			I = conf.getInt("I",0);
			K = conf.getInt("K",0);
			numGroups = conf.getInt("numGroups", 0);
			numGroupRows = I/numGroups;
			numGroupCols = K/numGroups;
			
			if (debug)
			{
				System.out.println("Is matrix M " + matrixM + " for "+ path);
			}
		}
		
		public void map(MatrixMultiply.IndexPair key,
				DoubleWritable val,Context context) throws IOException, InterruptedException
		{
			int i,j,k;
			double value = val.get();
			Text outputKey = new Text();
			Text outputValue = new Text();
			
			if (debug)
			{				
				System.out.println(matrixM ? "M matrix ":"N matrix");
				System.out.println("Map input: (" + key.row + "," + key.col + ") " +  val.get());
				System.out.println("Number of rows in each group " + numGroupRows);
			}
			if (matrixM)
			{				
				i = key.row;
				k = key.col;
				int rowGroupNum = i/numGroupRows;
				
				for (int g=0;g<numGroups;g++)
				{				
					outputKey.set(rowGroupNum + "," + g);
					outputValue.set("M," + i + "," + k + "," + value);
					context.write(outputKey,outputValue);
					if (debug)
					{
						System.out.println(matrixM ? "M matrix":"N matrix");
						System.out.println("Map output:key=" +outputKey+" value="+outputValue);
					}
				}				
			}
			else
			{
				k = key.row;
				j = key.col;
				int colGroupNum = j/numGroupCols;
				
				for (int g=0;g< numGroups;g++)
				{	
					outputKey.set(g + "," + colGroupNum);
					outputValue.set("N," + k + "," + j + "," + value);
					context.write(outputKey,outputValue);
					if (debug)
					{
						System.out.println(matrixM ? "M matrix":"N matrix");
						System.out.println("Map output:key=" +outputKey+" value="+outputValue);
					}
				}
			}
		}
	}
	public static class Map 
	extends Mapper<MatrixMultiply.IndexPair, 
	DoubleWritable,Text,Text>
	{
		private boolean matrixM;//are we mapping matrix M or N
		private Path path;
		private String inputPathM,inputPathN;
		private int I,J;
		private boolean debug = false;
		
		/**
		 * The Hadoop Map-Reduce framework spawns one map
		 * task for each InputSplit generated by the InputFormat 
		 * for this job. The framework first calls setup, 
		 * followed by map for each key/value pair in the 
		 * InputSplit
		 */
		public void setup(Context context)
		{
			Configuration conf = context.getConfiguration();
			inputPathM = conf.get("inputPathM");
			inputPathN = conf.get("inputPathN");
			debug = Boolean.parseBoolean(conf.get("debug"));
			FileSplit split = (FileSplit)context.getInputSplit();
			path = split.getPath();
			matrixM = path.toString().contains(inputPathM);
			I = conf.getInt("I",0);
			J = conf.getInt("J",0);
			
			if (debug)
			{
				System.out.println("Is matrix M " + matrixM + " for "+ path);
			}
		}
		
		public void map(MatrixMultiply.IndexPair key,
				DoubleWritable val,Context context) throws IOException, InterruptedException
		{
			int i,j,k;
			double value = val.get();
			Text outputKey = new Text();
			Text outputValue = new Text();
			
			if (debug)
			{				
				System.out.println(matrixM ? "M matrix ":"N matrix");
				System.out.println("Map input: (" + key.row + "," + key.col + ") " +  val.get());
			}
			if (matrixM)
			{
				//for as many columns of N
				for (j=0;j<J;j++)
				{
					i = key.row;
					k = key.col;
					outputKey.set(i + "," + j);
					outputValue.set("M," + k + "," + value);
					context.write(outputKey,outputValue);
					if (debug)
					{
						System.out.println(matrixM ? "M matrix":"N matrix");
						System.out.println("Map output:key=" +outputKey+" value="+outputValue);
					}
				}				
			}
			else
			{
				//for as many rows of M
				for (i=0;i<I;i++) 
				{
					k = key.row;
					j = key.col;
					outputKey.set(i + "," + j);
					outputValue.set("N," + k + "," + value);
					try{
						context.write(outputKey,outputValue);
					} catch(Exception ex) {
						ex.printStackTrace();
					}
					if (debug)
					{
						System.out.println(matrixM ? "M matrix":"N matrix");
						System.out.println("Map output:key=" +outputKey+" value="+outputValue);
					}
				}
			}
		}
	}
	
	public static class Partition extends Partitioner<Text,Text>
	{
		@Override
		public int getPartition(Text key,Text value,int numPartitions)
		{
			System.out.println("Reduce tasks " + numPartitions);
			return numPartitions;
		}
	}
	
	public static class ReduceGrouped extends Reducer<Text,
	Text,MatrixMultiply.IndexPair,DoubleWritable>
	{		
		boolean debug;
		int I,J;
		
		public void setup(Context context)
		{
			Configuration conf = context.getConfiguration();
			debug = Boolean.parseBoolean(conf.get("debug"));			
			I = conf.getInt("I",0);
			J = conf.getInt("J", 0);
		}
		
		public void reduce(Text key,
				Iterable<Text> values,Context context) throws IOException, InterruptedException
		{
			double pij;
			int i,j,k,lowI=I+1,highI=-1,lowJ=J+1,highJ=-1,colSize=-1;
			String[] value;
			java.util.Map<String,Double> mapM
			= new HashMap<String,Double>();
			java.util.Map<String,Double> mapN
			= new HashMap<String,Double>();
			for (Text val : values)
			{
				value = val.toString().split(",");
				i = Integer.parseInt(value[1]);
				j = Integer.parseInt(value[2]);
				if (value[0].equals("M"))
				{
					lowI = Math.min(lowI, i);
					highI = Math.max(highI, i);
					colSize = Math.max(colSize, j);
											
					mapM.put(i + "," + j,Double.parseDouble(value[3]));					
				}
				else
				{
					lowJ = Math.min(lowJ, j);
					highJ = Math.max(highJ, j);
					mapN.put(i + "," + j,Double.parseDouble(value[3]));										
				}
			}
			if (debug)
			{
				System.out.println("Reduce M map" + mapM);
				System.out.println("Reduce N map" + mapN);
				System.out.println("lowI=" + lowI + "highI=" + highI);
				System.out.println("lowJ=" + lowJ + "highJ=" + highJ);
				System.out.println("colSize=" + colSize);
			}
	
			for (i= lowI; i<= highI;i++)
			{
				for (j = lowJ; j<= highJ; j++)
				{
					pij = 0;
					for (k = 0; k<= colSize; k++)
					{							
						pij += mapM.get(i + "," + k) * mapN.get(k + "," +j); 
					}
					MatrixMultiply.IndexPair indexPair = new MatrixMultiply.IndexPair();
					indexPair.row = i;
					indexPair.col = j;
					DoubleWritable res = new DoubleWritable();
					res.set(pij);
			
					try
					{
						context.write(indexPair, res);
						if (debug)
						{
							System.out.println("Reduce output: i,j= " + key + "pij=" + res);
						}
					}
					catch (Exception ex)
					{
						ex.printStackTrace();
					}
				}
			}
		}
	}
	
	
	public static class Reduce extends Reducer<Text,
	Text,MatrixMultiply.IndexPair,DoubleWritable>
	{		
		boolean debug;
		int K;
		
		public void setup(Context context)
		{
			Configuration conf = context.getConfiguration();
			debug = Boolean.parseBoolean(conf.get("debug"));			
			K = conf.getInt("K",0);
		}
		
		public void reduce(Text key,
				Iterable<Text> values,Context context) throws IOException, InterruptedException
		{
			double mik,nkj, pij;
			String[] value;
			java.util.Map<Integer,Double> mapM
			= new HashMap<Integer,Double>();
			java.util.Map<Integer,Double> mapN
			= new HashMap<Integer,Double>();
			for (Text val : values)
			{
				value = val.toString().split(",");
				if (value[0].equals("M"))
				{
					mapM.put(Integer.parseInt(value[1]),Double.parseDouble(value[2]));					
				}
				else
				{
					mapN.put(Integer.parseInt(value[1]),Double.parseDouble(value[2]));										
				}
			}
			if (debug)
			{
				System.out.println("Reduce M map" + mapM);
				System.out.println("Reduce N map" + mapN);
			}
			pij = 0.0;
			for (int k=0; k<K;k++)
			{
				mik = mapM.containsKey(k) ? mapM.get(k) : 0.0;
				nkj = mapN.containsKey(k) ? mapN.get(k) : 0.0;
				pij += mik * nkj;
			}
			
			if (pij != 0.0)
			{
				MatrixMultiply.IndexPair indexPair = new MatrixMultiply.IndexPair();
				String indices[] = key.toString().split(",");
				indexPair.row = Integer.parseInt(indices[0]);
				indexPair.col = Integer.parseInt(indices[1]);
				DoubleWritable res = new DoubleWritable();
				res.set(pij);
			
				try
				{
					context.write(indexPair, res);
					if (debug)
					{
						System.out.println("Reduce output: i,j= " + key + "pij=" + res);
					}
				}
				catch (Exception ex)
				{
					ex.printStackTrace();
				}
			}
		}
	}

	
	@SuppressWarnings("deprecation")
	public static void run(Configuration conf) throws Exception
	{
		Job pass1 = new Job(conf,"Matrix multiplication pass 1 of 1");
		pass1.setJarByClass(OnePassMatrixMultiply.class);
		//pass1.setNumReduceTasks(2);//conf.getInt("numReduceTasks", 0));
		pass1.setInputFormatClass(SequenceFileInputFormat.class);
		pass1.setOutputFormatClass(SequenceFileOutputFormat.class);
		int groupSize = conf.getInt("groupSize", 0);
		if (groupSize<1)
		{
			pass1.setMapperClass(Map.class);
			pass1.setReducerClass(Reduce.class);
		}
		else
		{
			pass1.setMapperClass(MapGrouped.class);
			pass1.setReducerClass(ReduceGrouped.class);
		}
		//pass1.setPartitionerClass(Partition.class);
		pass1.setMapOutputKeyClass(Text.class);
		pass1.setMapOutputValueClass(Text.class);
		pass1.setOutputKeyClass(MatrixMultiply.IndexPair.class);
		pass1.setOutputValueClass(DoubleWritable.class);
		
		//The input files location
		FileInputFormat.addInputPath(pass1, new Path(conf.get("inputPathM")));
		FileInputFormat.addInputPath(pass1, new Path(conf.get("inputPathN")));
			
		//The output files location make sure you delete 
		//any previous setup
		FileSystem fs = FileSystem.get(conf);
		fs.delete(new Path(conf.get("outputPath")));
		FileOutputFormat.setOutputPath(pass1, new Path(conf.get("outputPath")));
		boolean passSuccess = pass1.waitForCompletion(true);
		if (!passSuccess)
		{
			throw new Exception("Pass 1 of 1 failed");
		}
	}
}
