There are 2 packages in this project:

MatrixMultiply
PageRank

a) In MatrixMultiply there are 3 classes with a main method 

To run the different mains from eclipse create a run/debug
configuration for each then enter arguments for command line.

or use the jar (to create a jar file from this project do from within 
Eclipse

Right Click the project->Export Java Jar file->Enter location
and name of jar)

To run one of the mains in the jar in a machine with hadoop 
installed type

./bin/hadoop jar jarname.jar matrixmultiply.ConversionMain true input_filename output_filename false path

or 
 
./bin/hadoop jar jarname.jar matrixmultiply.OnePassMatrixMultiplyMain 2 3 2 true optional_input_path optional_output_path 

or

./bin/hadoop jar jarname.jar matrixmultiply.TwoPassMatrixMultiplyMain 2 3 2 true optional_input_path optional_output_path optional_temp_path

(temp_path is the location where the output of step1 will be written to)

a.1) ConversionMain.java

This converts a file from binary to Hadoop SequenceFile or the other way
The command line arguments are

tobinary input_filename output_filename debug path

so to convert a given input_filename from binary to SequenceFile do

false input_filename output_filename false path_where_to_put_output_filename

to convert a given input_filename from SequenceFile to binary do

true input_filename output_filename false path_where_to_put_output_filename

if the path (last argument) is omitted the input and output files will be
read/written to a folder specified in the constant INPUT_PATH_FOLDER defined
at the top of ConversionMain.java
  
Note that the binary format consists of a first line with numrows numcols
then each line after that is one entry of the matrix in the order 
0 0
0 1
...
0 numcols-1
1 0
1 1
...
1 numcols-1
...
 
a.2) The arguments for OnePassMatrixMultiplyMain.java
are the dimensions
of the 2 matrices M (IxK) and N (KxJ), the number of groups and whether 
debugging should be enabled or not (if debug is on it will print out 
information along the different stages of the map reduce 
pipeline, including at the end if the map reduce matrix multiplication matches
regular matrix multiplication)
 
The number of groups should be a multiple of the size of both
matrices. So for 6x4x2 matrices use 2 groups, for
100x 100x1000 matrices use 5,10,20,25,50,100 (100 means that each row in 
the first matrix is in its own group and there are 100 groups of 10 columns each
in the second matrix).
  
 For 50x50x50 matrices (square matrices) note that choosing a grouping of
 1 means all rows/columns are in one group.

So the arguments for 2 groups would be

6 6 6 2 false optional_input_path optional_output_path

If not using grouping use 0 or -1 for the group argument
So enter say for the product of a 2x3 times by 3x2 matrix with 
no grouping

2 3 2 -1 false optional_input_path optional_output_path

a.2) No grouping was implemented for the 2 pass algorithm so the
arguments for TwoPassMatrixMultiplyMain.java are just the dimensions
of the 2 matrices

2 3 2 false optional_input_path optional_temp_path optional_output_path

for the product of a matrix 2x3 by a matrix 3x2

In both the one pass and the 2 pass algorithms the matrices are dense
i.e. none of their entries is zero. Also in both cases those matrices are
written to 2 different files called M and N in the input folder which are 
read by the mapper/first mapper.

Some examples of command line cmds  I ran in the apt cluster

One pass
-----------
/usr/local/hadoop-2.5.0/bin/hadoop jar /home/u0082100/matrixmultiply.jar matrixmultiply.OnePassMatrixMultiplyMain 100 1000 1000 10 false /user/u0082100/input/ /user/u0082100/output/

Two Pass
---------
/usr/local/hadoop-2.5.0/bin/hadoop jar /home/u0082100/matrixmultiply.jar matrixmultiply.TwoPassMatrixMultiplyMain 100 100 1000 false /user/u0082100/input/ /user/u0082100/output/ /user/u0082100/temp

Kill a job
-----------
/usr/local/hadoop-2.5.0/bin/hadoop job -kill job_1412285424336_1065
